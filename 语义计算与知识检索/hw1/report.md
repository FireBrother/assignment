# 词汇相关度计算

姓名：吴先

学号：1701214017

邮箱：wuxian94@pku.edu.cn

要求：实现三种词汇相关度计算方法，尽量保证方法的多样性

## 目录

[TOC]

## 实验环境

语言：python 3.6.2

使用工具包：sklearn, nltk, gensim

## 特征构建

本次实验使用了三种词汇相关度计算方法。

* 上下文向量
* 隐含语义分析
* word embedding

### 上下文向量

将每个待测试词表示为一个长度为字典长度的向量。取大小为5的上下文窗口，记录在上下文中这个维度表示的词的共现次数，作为这个待测试词的特征。

### 隐含语义分析

将<词汇，文章>的词频矩阵做奇异值分解，得到相应的词和文章向量。降维后的维数取100。实验中也尝试了使用tfidf矩阵作为分解对象，效果差异不大。

### Word Embedding

使用`gensim`提供的`Word2Vec`模型和相应算法。

## 实验设置

### 语料库

语料选择`nltk`提供的布朗语料库、路透社语料库和古腾堡语料库。语料规模数百万词。

布朗语料库收集了500个连贯英语书面语,每个文本超过2000词,整个语料库约1014300词。

NLTK包含古腾堡项目电子文本档案的一小部分文本。该项目目前大约有36000本免费的电子图书。

路透社语料库包括10788个新闻文档，共计130万字。

原本只使用了布朗语料库，但是规模太小，在word2vec的实验上无法取的可靠的效果，因此给所有方法扩展了语料库范围。

### 预处理

对英语单词进行小写、去停用词、词干提取的操作。

对待测试的词语也进行词干提取的操作。

### 距离度量和缺失值

距离度量采用基于余弦的相似度。具体为$0.5+0.5*cos(v_1+v_2)$。

如果待测试词没有出现在语料中，则直接返回相似度0.5。在所有待测试词中，有5个词有这个情况。

### 结果评价方式

因为我们的打分在0～1之间，人工打分在1～5之间，所以我们采用皮尔森相关系数对实验结果进行评价。

##结果与分析

| 方式           | 皮尔森相关系数 |
| -------------- | -------------- |
| 上下文向量     | 0.214          |
| 隐含语义分析   | 0.340          |
| word embedding | 0.339          |

在这个规模的语料上，LSA的效果与w2v的效果接近。两者都是通过降维将语义通过稠密向量表达出来的方式。上下文向量则因为稀疏、冗余等原因，效果不如前两者。

## 想法

度量语义相关度的指标和方法有很多。对于不同的语料和特征计算方法，并不存在一定好的距离/相似度度量方式，需要根据具体情况和模型原理进行适应。