# 《网络大数据管理理论和应用》期末考核

题目：根据本课程所覆盖的大数据管理和应用相关内容，学生设计一个面向某类应用的大数据管理平台，并完成平台的设计报告。

设计报告需包含以下内容：需求分析、现有相关工作调研、大数据管理平台概要设计、大数据管理平台各个模块设计等。 



姓名：吴先

学号：1701214017

日期：2018年1月15日



[TOC]

## 大数据管理平台类别

语料库管理分析平台。

## 需求分析

### 概要

在大数据背景下，语言本体研究，语言教学和语言应用研究离不开语料库的支持。 在语言本体研究中，大规模语料可以用来详尽地检验语言现象，可以用语言学理论或观点来总结，完善和验证。 实证方法也可以为语言学理论的研究提供数据支持和定量分析。 在教学过程中，语料库可以提供真实的语言材料，用来制作和解释教学内容，使语言教学内容选择和教学实施过程更加科学，可以支持字典和教材编写; 同时，语料库作为模型训练的知识库，在各种应用中起着不可或缺的作用。

历时语料库是在普通的语料库的基础上，加入时间轴，在时间维度上对语料进行划分并分析的语料库。一方面要面向数据库维护人员，方便进行数据的导入、预处理和管理工作；另一方面要面向研究者，提供基本的数据统计和分析，以及下载功能。因此，其主要需求为以下三点：

1. 对大规模非结构化数据进行有效、稳定的预处理和存储。
2. 支持高性能、多维度检索，对检索结果的统计、展示和下载等功能。
3. 支持后续科研成果向平台功能的转化。

### 用况分析

#### 数据库操作人员

1. 功能需求：非结构化数据预处理
   性能需求：每日新增数据在100TB级，要能够保证健壮性和吞吐量
2. 功能需求：海量数据存储
   性能需求：总量在PB级，峰值数据可能达到GB/s

#### 科研用户

1. 功能需求：数据库的实时查询和结果统计分析
   性能需求：对简单的查询需求，响应速度达到秒级；大规模数据的导出和组合查询，响应速度达到分钟级
2. 功能需求：查询结果的图形化展示和管理
3. 功能需求：在语料上进行多种机器学习算法的实现

## 相关工作

主要对北京语言大学语料库中心（BCC）和今日头条的大数据平台进行了调研。

其中对前者的调研侧重于功能点和处理流程，对后者的调研侧重于技术选型与实现。

### 北京语言大学语料库中心

“北京语言大学语料库中心(BCC)”(http://bcc.blcu.edu.cn)是以汉语为主、兼有其他语种的语言大数据，目标是为语言本体研究提供一个使用简便的在线检索系统和构建大数据的语言应用基础平台。BCC 支持云服务，通过 API 调用方式为开展知识抽取、模型构建等研究和应用工作提供便利。

主要包括三方面工作:语料库资源建设、检索引擎开发和提供语料库检索服务。如图 1 所示，语料库的资源建设是构建语料库数据内容的基础。BCC 主要包括三种类型语料:多语种单语语料库、双语对齐语料库和深加工的树库。语料库检索内核是实现语料库系统的技术基础，采用基于后缀串的全文检索算法，并且支持通配符和离合模式匹配。检索服务是指使用语料库系统的方式和方法。![屏幕快照 2018-01-15 下午3.27.14](/Users/wuxian/Documents/assignment/网络大数据/final/屏幕快照 2018-01-15 下午3.27.14.png)

#### 语料库资源建设

* 语料库涵盖多语种
* 多层次语料加工
* 现代古汉语语料和古代汉语语料兼具
* 汉语多语体
* 共时语料和历时语料兼具

#### 语料库采集加工平台

* 网上语料采集工具
* 语料技工整理工具
* 语言自动分析工具
* 语料库标注平台

#### 检索引擎

* 支持语言大数据
* 支持多语种检索
* 支持多语料检索
* 支持复杂检索

### 今日头条大数据平台

数据平台的需求最初来自推荐业务，从用户的阅读需求出发，搭建面向全公司的通用数据平台。其中，用户数据（内容偏爱、行为轨迹、阅读时间等）是头条最庞大的数据源，这些被记录下来的数据反映了用户的兴趣，会以各种形式传输和存储，并提供给全公司各个业务系统来调用。

还要维护面向 RD（分析师）数据工具集（日志收集、入库、调度、依赖管理、查询、元数据、报表），面向 PM、运营的通用用户行为分析平台，底层查询引擎（Hive，Presto，Kylin 等 OLAP 查询引擎，支撑上层数据平台和数据仓库），平台基础数据仓库及协助维护业务部门数据仓库。

#### 数据传输——Kafka 做消息总线连接在线和离线系统

数据在客户端向服务端回传或者直接在服务端产生时，可以认为是在线状态。当数据落地到统计分析相关的基础设施时，就变成离线的状态了。在线系统和离线系统采用消息队列来连接。

头条的数据传输以 Kafka 作为数据总线，所有实时和离线数据的接入都要通过 Kafka，包括日志、binlog 等。

#### 数据入库——数据仓库、ETL（抽取转换加载）

数据仓库中数据表的元信息都放在 Hivemetastore 里，数据表在 HDFS 上的存储格式以 Parquet 为主，这是一种列式存储格式，对于嵌套数据结构的支持也很好。

头条有多种 ETL 的实现模式在并存，对于底层数据构建，一种选择是使用 Python 通过 HadoopStreaming 来实现 Map Reduce 的任务，但现在更倾向于使用 Spark 直接生成 Parquet 数据，Spark 相比 MapReduce 有更丰富的处理原语，代码实现可以更简洁，也减少了中间数据的落地量。对于高层次的数据表，会直接使用 HiveSQL 来描述 ETL 过程。

#### 数据计算——计算引擎的演进

数据仓库中的数据表如何能被高效的查询很关键，因为这会直接关系到数据分析的效率。常见的查询引擎可以归到三个模式中，Batch 类、MPP 类、Cube 类，头条在 3 种模式上都有所应用。

头条现在的方案是混合使用 Spark SQL 和 Hive，并自研 QAP 查询分析系统，自动分析并分发查询 SQL 到适合的查询引擎。在 Cube 类查询引擎上，头条采用了 Kylin，现在也是Kylin 在国内最大的用户之一。

## 大数据平台架构设计

从需求出发，本项目设计的历时语料库管理分析平台是包含从数据预处理、存储、统计分析，直到检索和对结果的分析的完整平台。基于大规模分布式文件系统，并且提供足够的运算能力和检索能力。整个平台的架构如下：

![dc_arch](/Users/wuxian/Documents/assignment/网络大数据/final/dc_arch.png)

