# 《网络大数据管理理论和应用》期末考核

题目：根据本课程所覆盖的大数据管理和应用相关内容，学生设计一个面向某类应用的大数据管理平台，并完成平台的设计报告。

设计报告需包含以下内容：需求分析、现有相关工作调研、大数据管理平台概要设计、大数据管理平台各个模块设计等。 



姓名：吴先

学号：1701214017

日期：2018年1月15日



[TOC]

## 大数据管理平台类别

语料库管理分析平台。

## 需求分析

### 概要

在大数据背景下，语言本体研究，语言教学和语言应用研究离不开语料库的支持。 在语言本体研究中，大规模语料可以用来详尽地检验语言现象，可以用语言学理论或观点来总结，完善和验证。 实证方法也可以为语言学理论的研究提供数据支持和定量分析。 在教学过程中，语料库可以提供真实的语言材料，用来制作和解释教学内容，使语言教学内容选择和教学实施过程更加科学，可以支持字典和教材编写; 同时，语料库作为模型训练的知识库，在各种应用中起着不可或缺的作用。

历时语料库是在普通的语料库的基础上，加入时间轴，在时间维度上对语料进行划分并分析的语料库。一方面要面向数据库维护人员，方便进行数据的导入、预处理和管理工作；另一方面要面向研究者，提供基本的数据统计和分析，以及下载功能。因此，其主要需求为以下三点：

1. 对大规模非结构化数据进行有效、稳定的预处理和存储。
2. 支持高性能、多维度检索，对检索结果的统计、展示和下载等功能。
3. 支持后续科研成果向平台功能的转化。

### 用况分析

#### 数据库操作人员

1. 功能需求：非结构化数据预处理
   性能需求：每日新增数据在100TB级，要能够保证健壮性和吞吐量
2. 功能需求：海量数据存储
   性能需求：总量在PB级，峰值数据可能达到GB/s

#### 科研用户

1. 功能需求：数据库的实时查询和结果统计分析
   性能需求：对简单的查询需求，响应速度达到秒级；大规模数据的导出和组合查询，响应速度达到分钟级
2. 功能需求：查询结果的图形化展示和管理
3. 功能需求：在语料上进行多种机器学习算法的实现

## 相关工作

主要对北京语言大学语料库中心（BCC）和今日头条的大数据平台进行了调研。

其中对前者的调研侧重于功能点和处理流程，对后者的调研侧重于技术选型与实现。

### 北京语言大学语料库中心

“北京语言大学语料库中心(BCC)”(http://bcc.blcu.edu.cn)是以汉语为主、兼有其他语种的语言大数据，目标是为语言本体研究提供一个使用简便的在线检索系统和构建大数据的语言应用基础平台。BCC 支持云服务，通过 API 调用方式为开展知识抽取、模型构建等研究和应用工作提供便利。

主要包括三方面工作:语料库资源建设、检索引擎开发和提供语料库检索服务。如图 1 所示，语料库的资源建设是构建语料库数据内容的基础。BCC 主要包括三种类型语料:多语种单语语料库、双语对齐语料库和深加工的树库。语料库检索内核是实现语料库系统的技术基础，采用基于后缀串的全文检索算法，并且支持通配符和离合模式匹配。检索服务是指使用语料库系统的方式和方法。![屏幕快照 2018-01-15 下午3.27.14](/Users/wuxian/Documents/assignment/网络大数据/final/屏幕快照 2018-01-15 下午3.27.14.png)

#### 语料库资源建设

* 语料库涵盖多语种
* 多层次语料加工
* 现代古汉语语料和古代汉语语料兼具
* 汉语多语体
* 共时语料和历时语料兼具

#### 语料库采集加工平台

* 网上语料采集工具
* 语料技工整理工具
* 语言自动分析工具
* 语料库标注平台

#### 检索引擎

* 支持语言大数据
* 支持多语种检索
* 支持多语料检索
* 支持复杂检索

### 今日头条大数据平台

数据平台的需求最初来自推荐业务，从用户的阅读需求出发，搭建面向全公司的通用数据平台。其中，用户数据（内容偏爱、行为轨迹、阅读时间等）是头条最庞大的数据源，这些被记录下来的数据反映了用户的兴趣，会以各种形式传输和存储，并提供给全公司各个业务系统来调用。

还要维护面向 RD（分析师）数据工具集（日志收集、入库、调度、依赖管理、查询、元数据、报表），面向 PM、运营的通用用户行为分析平台，底层查询引擎（Hive，Presto，Kylin 等 OLAP 查询引擎，支撑上层数据平台和数据仓库），平台基础数据仓库及协助维护业务部门数据仓库。

#### 数据传输——Kafka 做消息总线连接在线和离线系统

数据在客户端向服务端回传或者直接在服务端产生时，可以认为是在线状态。当数据落地到统计分析相关的基础设施时，就变成离线的状态了。在线系统和离线系统采用消息队列来连接。

头条的数据传输以 Kafka 作为数据总线，所有实时和离线数据的接入都要通过 Kafka，包括日志、binlog 等。

#### 数据入库——数据仓库、ETL（抽取转换加载）

数据仓库中数据表的元信息都放在 Hivemetastore 里，数据表在 HDFS 上的存储格式以 Parquet 为主，这是一种列式存储格式，对于嵌套数据结构的支持也很好。

头条有多种 ETL 的实现模式在并存，对于底层数据构建，一种选择是使用 Python 通过 HadoopStreaming 来实现 Map Reduce 的任务，但现在更倾向于使用 Spark 直接生成 Parquet 数据，Spark 相比 MapReduce 有更丰富的处理原语，代码实现可以更简洁，也减少了中间数据的落地量。对于高层次的数据表，会直接使用 HiveSQL 来描述 ETL 过程。

#### 数据计算——计算引擎的演进

数据仓库中的数据表如何能被高效的查询很关键，因为这会直接关系到数据分析的效率。常见的查询引擎可以归到三个模式中，Batch 类、MPP 类、Cube 类，头条在 3 种模式上都有所应用。

头条现在的方案是混合使用 Spark SQL 和 Hive，并自研 QAP 查询分析系统，自动分析并分发查询 SQL 到适合的查询引擎。在 Cube 类查询引擎上，头条采用了 Kylin，现在也是Kylin 在国内最大的用户之一。

## 大数据平台概要设计

从需求出发，本项目设计的历时语料库管理分析平台是包含从数据预处理、存储、统计分析，直到检索和对结果的分析的完整平台。基于大规模分布式文件系统，并且提供足够的运算能力和检索能力。整个平台的架构如下：

![dc_arch](/Users/wuxian/Documents/assignment/网络大数据/final/dc_arch.png)

平台共分为5个模块，分别是数据预处理层、数据存储层、数据存储层、数据计算、检索与统计分析模块和自定义算法模块。管理员负责整个架构的开发和维护，科研用户利用基于数据计算层的检索与统计分析结果进行研究，而内部的研发团队可以利用研究成果，将算法加入自定义算法模块，甚至固化到数据计算层，提供更丰富的检索方式。

平台旨在提供大规模语料与多维检索的解决方案，并尽可能加快学术界成果向工业界的转换速度。通过加入对第三方开放的自定义算法模块，集合更多科研用户的智慧。

将数据预处理层和数据计算层解耦。数据计算层与数据预处理层分属存储层的两端，预处理关注的是从非结构化文本中提取出结构化存储所需要的特征，这个过程可以看成是动态的；经过存储层落地成静态数据；而在计算层，才能在静态数据上进行传统的数据挖掘工作。

## 模块设计

### 数据预处理层

数据预处理层使用Kafka作为数据总线。

传入的新的非结构化数据是生产者产生的资料，由分布式服务器群构成的预处理服务器是消费者。消费者机器上部署相应的预处理算法，相互使用thrift协议进行通信。

选择Apache Avro作为统一的数据格式。Avro是一种类似JSON的数据模型，可以用JSON或二进制形式进行表示。它可以与JSON直接映射，有一个非常紧凑的格式，效率非常高，而且提供了到多种编程语言的绑定，是一个用纯JSON定义的、可扩展的模式语言。

![0330002](/Users/wuxian/Documents/assignment/网络大数据/final/0330002.png)

在流处理过程中，将处理结果重新发布到Kafka中。它将流处理的各部分解耦，不同的处理任务可以由不同的团队使用不同的技术实现，下游处理过程缓慢不会对上游过程造成反压，Kafka起到了缓冲区的作用。



### 数据存储层

数据存储层使用HBase对数据进行存储。同时在服务器集群上部署Hadoop，每个节点兼具存储与运算功能。这里Hadoop提供的运算功能是用于为数据计算层提供基础的计算支持的。

存储单元具有冗余备份系统，保证数据的完整性。对于大规模的文本语料而言，尽量选取非关系型的数据存储方案，并且建立信息量足够多的索引，尽可能减少在线检索时的性能压力。

从Kafka得到的数据在数据存储层落地至HDFS，用于为后续计算和检索任务提供静态数据。所以存储层一方面需要提供持续的增量式存储，另一方面也要能承受大规模数据导入的峰值压力。

### 数据计算层

数据计算层需要部署一系列自然语言处理模型和数据挖掘模型。

从计算模型的角度，要提供SQL模型，处理TB、PB级的海量数据；提供MapReduce模型，用于加速分布式算法的开发。为算法提供基础的数据计算支持。

从算法模型的角度，短语抽取、主题模型、聚类算法、向量空间模型等算法和模型也需要加入其中，用于为上层检索等服务提供更丰富的特征和角度。

计算出的特征数据可以使用mongo db等更为灵活的非关系型数据库存储和维护

### 检索和统计分析模块

检索模块使用Lucene和ElasticSearch进行全文和索引检索。

一个集群由一个或多个节点组织在一起，它们共同持有整个的数据，并一起提供索引和搜索功能。一个节点是集群中的一个服务器，作为集群的一部分，它负责存储数据，参与集群的索引和搜索功能。Elasticsearch提供了将索引划分成多份的能力，这些份就叫做分片。当创建一个索引的时候，可以指定你想要的分片的数量。每个分片本身也是一个功能完善并且独立的“索引”，这个“索引”可以被放置到集群中的任何节点上。

统计分析模块将检索结果进行初步的分析并以表格、图表等方式进行展示。